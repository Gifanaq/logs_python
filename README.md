# Анализатор логов NGINX (Log Analyzer)
Консольная утилита для автоматизированного сбора и анализа статистики NGINX серверов. Инструмент позволяет обрабатывать локальные и удаленные лог-файлы, генерируя подробные отчеты о состоянии трафика.
# 1. Описание проекта
Программа предназначена для эффективной обработки логов в формате NGINX. Основной акцент сделан на производительности: утилита использует потоковое чтение, что позволяет анализировать файлы объемом в несколько гигабайт без перегрузки оперативной памяти
# 2. Основные возможности
Гибкие источники: Поддержка локальных путей (с использованием glob-шаблонов) и прямых URL-ссылок.

Многоформатность: Экспорт результатов в Markdown, JSON или AsciiDoc.

Временные фильтры: Возможность ограничить анализ конкретным периодом (параметры --from и --to в формате ISO8601).

Расширенная статистика: Расчет среднего, максимального и 95-го перцентиля размера ответов.

Анализ ресурсов: Выявление топ-10 самых востребованных URI и частоты кодов ответа.
# 3. Установка и запуск
Требования
Python 3.8 или выше.

Доступ к сети (для обработки удаленных логов).
python```
python main.py --path "logs/2025*" --format markdown --output report.md --from 2025-01-01
```
Параметр,Описание,Обязательный
"--path, -p","Путь к логам (файл, URL или маска /logs/*.log)",Да
"--output, -o",Путь к файлу для сохранения отчета,Да
"--format, -f","Формат вывода: markdown, json, adoc",Нет
--from,Начальная дата фильтрации (ISO8601),Нет
--to,Конечная дата фильтрации (ISO8601),Нет

# 5. Собираемая статистика
Программа агрегирует данные и выдает результат с точностью до 2 знаков после запятой:

Общее кол-во запросов.

Статистика размеров ответов: среднее значение, максимум, 95% перцентиль.

Ресурсы: топ-10 запрашиваемых путей (без учета метода запроса).

Коды ответов: распределение всех встреченных статус-кодов.

Дополнительно: распределение запросов по дням недели и список уникальных протоколов (HTTP/1.1, HTTP/2 и др.).

# 6. Обработка данных и ошибки
Алгоритм работы
Загрузка: Итеративное чтение источника (локально или через стриминг HTTP-запроса).

Парсинг: Каждая строка проверяется на соответствие стандартному формату логов NGINX.

Валидация: Если строка повреждена, записывается WARN лог в stdout, а строка пропускается.

Агрегация: Данные накапливаются в памяти в виде счетчиков и списков для расчета квантилей.

Коды возврата
0 — Успех.

1 — Критическая системная ошибка.

2 — Ошибка валидации (неверные пути, даты или форматы).

# 7. Тестирование
Проект придерживается принципов надежности:

Минимальное покрытие тестами — 50%.

Реализованы Blackbox-тесты для проверки корректности CLI-интерфейса.

Используются модульные тесты для логики расчета перцентилей и парсинга дат.

Для запуска тестов используйте:
python```
pytest
```
# 8. Лицензия
Проект лицензирован в соответствии с условиями MIT License.
